#+author: Ragnar Groot Koerkamp
#+HUGO_BASE_DIR: .
#+HUGO_SECTION: notes
#+HUGO_AUTO_SET_LASTMOD: t
#+bibliography: local-bib.bib
#+cite_export: csl chicago-author-date.csl

* Hello, World!
CLOSED: [2021-10-13]
:PROPERTIES:
:EXPORT_FILE_NAME: hello-world
:END:
#+BEGIN_SRC python
print("Hello, World!")
#+END_SRC
#+BEGIN_SRC cpp
std::cout << "Hello, World!" << std::endl;
#+END_SRC

* Hugo and ox-hugo :hugo:org:
CLOSED: [2021-10-14]
:PROPERTIES:
:EXPORT_FILE_NAME: hugo
:END:
Here's the customary /how I made this site using X/ post.

This site is built using [[https://gohugo.io][Hugo]] and [[https://ox-hugo.scripter.co/][~ox-hugo~]].

The source is written in [[https://orgmode.org/][Org mode]], which is converted to markdown by ~ox-hugo~.
To get started yourself, check out the [[https://github.com/RagnarGrootKoerkamp/research/tree/c46e8c7840d70b86746ebe1d76384893638d8bbc][initial commit]] of the source repository
and build from there.

Some notes:
- I'm using the ~Hugo-coder~ theme.
- Since the conversion from Org to markdown is done using an Emacs plugin, the
  ~emacs~ folder contains a simple ~init.el~ to import ~ox-hugo~ and a function
  to export all ~*.org~ files in the repository apart from those inside the
  ~emacs~ folder itself.
- The ~makefile~ contains the ~build-content~ rule to call the conversion, and
  ~build-site~ to invoke Hugo. Just running ~make~ will do both of these and
  serve the site locally.

* TODO list :todo:
CLOSED: [2021-10-20 Wed 14:07]
:PROPERTIES:
:EXPORT_FILE_NAME: todo
:END:

- Fix latex rendering (katex vs mathjax; markdown engine configuration)
- Post on suffix array construction algorithms

* DONE 1st law of Procrastination :observation:quote:
CLOSED: [2021-10-22 Fri 11:46]
:PROPERTIES:
:EXPORT_FILE_NAME: procrastination
:END:
Important deadlines require important procrastination.

* DONE Data should be reviewed :observation:
CLOSED: [2021-10-22 Fri 11:41]
:PROPERTIES:
:EXPORT_FILE_NAME: data-should-be-reviewed
:END:
Experiments and their analysis should be reproducible, and all data/figures in a
paper should be reviewable. Pipelines (e.g. ~snakemake~ files) to generated them
should be attached to the paper.

I've asked for automated scripts to reproduce test data on 3+ github repositories
now, and got a satisfactory answer zero times:

- WFA: https://github.com/smarco/WFA/issues/26

  Link to a datadump on the block-aligner repository. Good to have actual data,
  but /exactly/ how this data was created is unclear to me.
- WFAlm: https://github.com/jeizenga/wfalm/issues/6

  Some manual scripts to be invoked -- high probability of manual error, and I
  have to use tools I do not fully understand since I have not used them before.
- BiWFA: https://github.com/smarco/BiWFA-paper/issues/1 (pending)



* DONE RTFE :quote:
CLOSED: [2021-10-22 Fri 15:16]
:PROPERTIES:
:EXPORT_FILE_NAME: rfte
:END:
Read The F*ing Error

- When you complain about an error without reading it first.
- When you assume you understand the problem halfway through reading the error,
  and only after more debugging you realize you failed to read properly.

* DONE Gap-close cost for diagonal transition
CLOSED: [2022-04-17 Sun 03:14]
:PROPERTIES:
:EXPORT_FILE_NAME: affine-gap-close-cost
:END:

*Xrefs:* [[https://github.com/smarco/BiWFA-paper/issues/4][BiWFA GitHub issue]]

[cite/text:@biwfa] introduces the classic divide-and-conquer approach of
[cite/text:@hirschberg75] to their WFA [cite:@wfa] algorithm.

In this, they run their *gap-open* affine cost variant of the diagonal transition
method from both ends towards the middle of the sequence until they overlap.
This has the drawback that the sides need to run until $s_l + s_r \geq s + o$,
where $s_l$ and $s_r$ are the distances 'searched' from the start and end
respectively, $s$ is the total cost, and $o$ is the gap open penalty.

I think it is possible to change the gap-open affine cost model to a *gap-close*
affine cost model, so that the meet-in-the-middle can be stopped as soon as the
two fronts touch, instead of when they overlap sufficiently.

The original WFA recursion is this (copied from the BiWFA paper, [cite/text:@biwfa]):
\begin{align}
I_{s,k} &= \max\big\{M_{s-o-e,k-1}-1, I_{s-e,k-1}+1\big\}\\
D_{s,k} &= \max\big\{M_{s-o-e,k+1}, D_{s-e,k+1}\big\}\\
X_{s,k} &= \max\big\{M_{s-x,k}+1, I_{s,k}, D_{s,k}\big\}\\
M_{s,k} &= X_{s,k} + LCP\big(A[X_{s,k}-k \dots], B[X_{x,k}\dots]\big)
\end{align}
where $LCP$ is the length of the longest common prefix of the two strings.

I propose the following recursion, which only adds the cost $o$ when $I$ and $D$ are
/merged/ into a matching state $M$ (or $X$), instead of adding it when /branching off/ a
matching state $M$.
\begin{align}
I_{s,k} &= \max\big\{M_{s-e,k-1}-1, I_{s-e,k-1}+1\big\}\\
D_{s,k} &= \max\big\{M_{s-e,k+1}, D_{s-e,k+1}\big\}\\
X_{s,k} &= \max\big\{M_{s-x,k}+1, I_{s-o,k}, D_{s-o,k}\big\}\\
M_{s,k} &= X_{s,k} + LCP\big(A[X_{s,k}-k \dots], B[X_{x,k}\dots]\big).
\end{align}
Here it is again, but with additions in green and deletions in red:
\begin{align}
I_{s,k} &= \max\big\{M_{s\mathbf{\color{red}-o}-e,k-1}-1, I_{s-e,k-1}+1\big\}\\
D_{s,k} &= \max\big\{M_{s\mathbf{\color{red}-o}-e,k+1}, D_{s-e,k+1}\big\}\\
X_{s,k} &= \max\big\{M_{s-x,k}+1, I_{s\mathbf{\color{lime}-o},k}, D_{s\mathbf{\color{lime}-o},k}\big\}\\
M_{s,k} &= X_{s,k} + LCP\big(A[X_{s,k}-k \dots], B[X_{x,k}\dots]\big).
\end{align}

Alternatively, the formulas could be made symmetric by incurring a cost of $o/2$
to open a gap and a cost of $o/2$ when closing a gap:
\begin{align}
I_{s,k} &= \max\big\{M_{s\mathbf{\color{lime}-o/2}-e,k-1}-1, I_{s-e,k-1}+1\big\}\\
D_{s,k} &= \max\big\{M_{s\mathbf{\color{lime}-o/2}-e,k+1}, D_{s-e,k+1}\big\}\\
X_{s,k} &= \max\big\{M_{s-x,k}+1, I_{s\mathbf{\color{lime}-o/2},k}, D_{s\mathbf{\color{lime}-o/2},k}\big\}\\
M_{s,k} &= X_{s,k} + LCP\big(A[X_{s,k}-k \dots], B[X_{x,k}\dots]\big).
\end{align}


** References

#+print_bibliography:
* DONE Motivation
CLOSED: [2022-04-28 Thu 23:22]
:PROPERTIES:
:EXPORT_FILE_NAME: motivation
:END:
It's not the need for faster software that motivates; it's the mathematical
  discovery that needs sharing.
* DONE Benchmark attention points
CLOSED: [2022-04-28 Thu 23:33]
:PROPERTIES:
:EXPORT_FILE_NAME: benchmarks
:END:
- Pin CPU frequency ::
  CPUs, especially laptops, have turboboost, (thermal) throttling, and powersave
  features. Make sure to pin the CPU core frequency low enough that it can be
  sustained for long times without throttling.

  In my case, the `performance` governor can fix the CPU frequency. The base
  frequency of my CPU is ~2.6GHz~, but I set it slightly lower since I prefer consistency.
  #+BEGIN_SRC shell
  sudo cpupower frequency-set -g performance
  sudo cpupower frequency-set -u 1.8GHz
  sudo cpupower frequency-set -d 1.8GHz
  #+END_SRC
- Pin program to core ::
  Make sure your program only executes on one core. Do this using e.g.
  #+begin_src shell
  taskset -c 0 <shell invocation>
  #+end_src
  When running multiple experiments in parallel, use distincs ids instead of ~0~.
- Do not use hyper threads ::
  Never use both hyper threads of a single core. On my 6-CPU machine, thread ~i~
  and thread ~i+6~ share their core, so I only use threads with id ~0~ to ~5~.
- Limit number of CPUs used ::
  Memory bound programs share resources, even if running on disjoint CPUs. In my
  case, using all 6 cores gives a ~30%~ slowdown compared to only using 1 core
  at a time (on some specific experiment).
  Using 3 cores gives only ~10%~ slowdown, which is acceptable.
- Use a low job niceness ::
  At any point in time, multiple jobs need CPU resources. Use a low job
  /niceness/ (like ~-20~) to give your experiment a higher priority. As an example,
  input (keyboard) and audio processing usually runs with a low niceness.
