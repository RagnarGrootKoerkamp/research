#+TITLE: A history of exact pairwise alignment
#+HUGO_BASE_DIR: ../..
#+HUGO_CATEGORIES: posts methods
#+HUGO_TAGS: pairwise-alignment
#+HUGO_LEVEL_OFFSET: 1
# NOTE: Run citar-export-local-bib-file to generate local-bib.bib.
# +BIBLIOGRAPHY: /home/philae/git/eth/references/references.bib
#+BIBLIOGRAPHY: local-bib.bib
#+cite_export: csl
#+OPTIONS: ^:{}
#+footnote-define-inline: t
#+date: <2022-03-24 Thu>

This post lists some of the more relevant papers and implementations related to
pairwise alignment.

First, lets quickly go over the existing variants of the pairwise alignment problem.

---

* Variants of pairwise alignment

Pairwise alignment is the problem of finding the lowest cost way to transform a
string $A$ of length $n$ into a string $B$ of length $m$ using some set of
operations, each with their own cost.

** Cost models
See the [[https://github.com/smarco/WFA2-lib][WFA2 readme]] for more detail.
Note that some models minimize the cost, while others include a score for
matching characters and maximize.
- Indel / LCS [[[https://en.wikipedia.org/wiki/Longest_common_subsequence_problem][wikipedia]]] :: No substitutions allowed. Count minimum number of
  indels, that is, insertions or deletions.
- Edit / Levenshtein distance [[[https://en.wikipedia.org/wiki/Levenshtein_distance][wikipedia]]] :: Minimum number of indels and/or substitutions needed. All
  cost $1$.
- Arbitrary :: Arbitrary substitution cost $\delta(a, b)$ for matches/mismatches
  between characters $a$ and $b$, and arbitrary cost $w(l)$ for a gap of length
  $l$. Usually $\delta(a,b)\leq 0$ if $a=b$ and $\delta(a,b)>0$ if $a\neq b$.
- Gap-linear :: The cost of a gap is given by the sum of costs to insert/delete
  all characters, $\delta(-, b)>0$ resp. $\delta(a, -)>0$.
- Gap-affine :: Variant of gap-linear, where
  gap costs are affine, i.e. linear with an offset.
  There are costs $O$ (/open/) and $E$ (/extend/), and the cost
  of a gap of length $l$ is $w(l) = O + l\cdot E$.
- Dual-cost gap-affine :: Introduce two gap scores based on $(O_1, E_1)$ and
  $(O_2, E_2)$. The cost of a gap of length $l$ is $w(l) = \min(O_1 + l\cdot E_1, O_2 +
  l\cdot E_2)$.
- Convex :: $w(l)$ is a convex function of $l$, where longer gaps are relatively
  more expensive.
- Concave :: $w(l)$ is a concave function of $l$, where longer gaps are relatively
  cheaper. Gap-affine costs are also concave.
In practice, most methods use a match cost $\delta(a,a) = 0$, fixed mismatch
cost $\delta(a,b) = X>0$ for $a\neq b$, and fixed indel cost
$\delta(a,-) = \delta(-,b) = I$.

** Alignment modes
- Global :: Align both sequences fully, end-to-end.
- Ends-free :: Indels/gaps at the end are free.
  - Glocal / semi-global / mapping :: Map a read to a substring of a reference.
  - Extension :: Anchor both at their starts, but one is longer.
  - Overlap :: Align two partially overlapping reads against each other.
- Local :: Aligns a substring of $A$ to a substring of $B$. Like ends-free, but
  now we may skip the and and start of both sequences.

Some alignment modes, in particular local and overlap, typically use a different
cost model where matching characters get a bonus.

** Parameters for the runtime
These variables are used for asymptotic complexity and memory usage.
- $n$, $m$: sequence lengths. I consistently assume $n\geq m$, but some papers differ.
- $d$: edit distance;
- $s$: alignment cost (or occasionally edit distance), given some cost model;
- $p$: length of LCS;
- $r$: the number of pairs of matching characters between the two sequences;
- $|\Sigma|$: alphabet size.

---

* A chronological overview

Here is a chronological summary, assuming finite alphabets where needed.
Multiple algorithms in a paper get separate rows. $n\geq m$.  Time/space
improvements and new ideas are bold.  Unless mentioned otherwise, all these
methods are *exact* (i.e. provable correct) and do *global alignment*.

| Paper                                                  | Time                                        | Space                                | Cost model                   | Methods                                                         | Remarks                                                     |
|--------------------------------------------------------+---------------------------------------------+--------------------------------------+------------------------------+-----------------------------------------------------------------+-------------------------------------------------------------|
| [cite/text/cf:@nw]                                     | $O(n^2m)$                                   | $O(nm)$                              | arbitrary                    | *DP^{[[NW]]}*                                                       |                                                             |
| [cite/text/cf:@sankoff]                                | $\boldsymbol{O(nm)}$                        | $O(nm)$                              | LCS                          | *DP*                                                            |                                                             |
| *[cite/text/cf:@sellers] and [cite/text/cf:@wagner74]* | $O(nm)$                                     | $O(nm)$                              | *gap-linear*                 | *NW DP^{[[NW]]}*                                                    |                                                             |
| *[cite/text/cf:@hirschberg75]*                         | $O(nm)$                                     | $\boldsymbol{O(\min(n,m))}$          | LCS                          | *divide-and-conquer*                                            | introduces linear memory backtracking                       |
| [cite/text/cf:@hunt77]                                 | $\boldsymbol{O((r+n)\lg n)}$                | $O(r+n)$                             | LCS                          | *thresholds*                                                    | distance only                                               |
| [cite/text/cf:@hirschberg77]                           | $\boldsymbol{O(pn +n \lg\vert\Sigma\vert)}$ | ?                                    | LCS                          | *contours*                                                      | introduces $k$-candidates                                   |
| [cite/text/cf:@hirschberg77]                           | $\boldsymbol{O(p(m-p)\lg n)}$               | $\boldsymbol{O(n+(m-p)^2)}$          | LCS                          | ... + band                                                      |                                                             |
| [cite/text/cf:@four-russians-ed]                       | $\boldsymbol{O(nm/\lg n)}$                  | $O(n^2/\lg n)$^{[[score-only]]}          | gap-linear^{[[discrete-scores]]} | *four Russians*                                                 | best worst case complexity                                  |
| [cite/text/cf:@sw]                                     | $O(n^2m)$                                   | $O(nm)$                              | arbitrary                    | DP^{[[SWG]]}                                                        | local alignment                                             |
| *[cite/text/cf:@gotoh]^{[[bugfix]]}*                       | $O(nm)$                                     | $O(nm)$^{[[score-only]]}                 | *gap-affine^{[[gap-affine]]}*    | *SWG DP^{[[SWG]]}*                                                  |                                                             |
| [cite/text/cf:@nakatsu82]                              | $\boldsymbol{O(n(m-p))}$                    | $O(n(m-p))$                          | LCS                          | *thresholds DP*                                                 |                                                             |
| *[cite/text/cf:@ukkonen85]*                            | $\boldsymbol{O(ns)}$                        | $O(ns)$^{[[score-only]]}                 | gap-linear                   | *exponential search on band*                                    |                                                             |
| *[cite/text/cf:@ukkonen85]*                            | $O(s\cdot \min(m,n))$                       | $\boldsymbol{O(n+s^2)}$^{[[score-only]]} | edit cost                    | *diagonal transition^{[[diagonal-transition]]}*                     | furthest reaching points                                    |
| *[cite/text/cf:@myers86]*                              | $O(nd)$                                     | $O(n)$                               | LCS                          | *diagonal transition^{[[diagonal-transition]]}*, divide-and-conquer | $O(n+d^2)$ expected time                                    |
| *[cite/text/cf:@myers86]*                              | $\boldsymbol{O(n +d^2)}$                    | $O(n)$                               | LCS                          | ... + *suffix tree*                                             |                                                             |
| My observation [find paper?]                           | $\boldsymbol{O(n +s^2)}$                    | $O(n+s^2)$^{[[score-only]]}              | edit cost                    | suffix tree                                                     | apply suffix tree to [cite/text:@ukkonen85]                 |
| [cite/text/cf:@myers88]                                | $O(nm)$                                     | $O(\min(n,m))$                       | gap-affine                   | divide-and-conquer                                              | improves [cite/text:@gotoh] using [cite/text:@hirschberg75] |
| [cite/text/cf:@lv89]                                   | $O(nk)$                                     | $\boldsymbol{O(n)}$                  | edit cost                    | suffix tree                                                     | $k$-approximate string matching                             |

1. <<NW>> Confusingly, nowadays [[https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm][Needleman-Wunsch (NW)]] is used to refer to the quadratic
   global alignment algorithm introduced by [cite:@sellers;@wagner74]. [cite/text/c:@gotoh] refers to it as
   Needleman-Wunsch-Sellers' algorithm. See also the wiki page on [[https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm][Wagner-Fisher]].
2. <<discrete-scores>> The four Russians algorithm of [cite/text:@four-russians-ed] needs discrete scores and a finite alphabet.
3. <<SWG>> Smith-Waterman-Gotoh (SWG), refers to the gap-affine global alignment
   algorithm introduced in [cite/text:@gotoh].

   On the other hand, [[https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm][Smith-Waterman (SW)]] refers to a quadratic algorithm for
   local alignment.  [cite/text/c:@sw] introduce the cubic recursion for local
   search, and while the technique of [cite/text/c:@gotoh] speeds it up to
   quadratic, that paper does not explicitly state the recursion for the case of
   local alignment.
3. <<score-only>> When only the score is needed, and not an alignment, these
   methods only need $O(n)$ memory.
4. <<bugfix>> [cite/text/c:@altschul] fixes a bug in the backtracking algorithm of [cite/text:@gotoh].
5. <<gap-affine>> [cite/text/c:@waterman] explores non-linear cost
   functions, and gives an example where gaps of size $2$ are cheaper than gaps
   of size $1$. [cite/text/c:@smith81] mentions gap-affine costs in its
   discussion. This [cite:@gotoh] is the first algorithm exploiting the
   structure of gap-affine costs.
6. <<diagonal-transition>> [cite/text/c:@ukkonen85] and [cite/text:@myers86]
   independently introduced the diagonal transition method in parallel.


** Important results

[TODO: Explain some of the more important results, including figures from the papers]
- Cubic NW
- quadratic NW
- linear memory traceback of Hirschberg'75
- thresholds, k-matches, contours (LCS)
- furthest reaching points, diagonal transition, wavefront (gap linear, gap affine)
- Theoretical lower bound $O(n)$


#+caption: The cubic algorithms of [cite/text:@nw].
[[file:nw.png]]




- [cite/text/cf:@gotoh] ::
  It uses three matrices $D$,
  $P$, and $Q$, where $P$ and $Q$ correspond to the minimal alignment cost when
  ending with a deletion or insertion respectively.

- [cite/text/cf:@hunt77] [[[https://en.wikipedia.org/wiki/Hunt%E2%80%93Szymanski_algorithm][wikipedia]]] :: An $O((r+n) \lg n)$ algorithm for LCS, for $r$ ordered pairs
  of positions where the two sequences match, using an array of /threshold
  values/ $T_{i,k}$: the smallest $j$ such that the prefixes of length $i$ and
  $j$ have an LCS of length $k$. Faster than quadratic for large alphabets (e.g.
  lines of code).
- [cite/text/cf:@hirschberg77] :: Defines /$k$-candidates/ (already introduced in Hirschberg's
  thesis two years before) as matches where a LCS of length $k$ ends. /Minimal/
  (also called /essential/ elsewhere) $k$-candidates are those for which there
  are no other /smaller/ $k$-candidates.  This leads to /contours/: the border
  between regions of equal $L$-value, and an $O(pn+n\lg n)$ algorithm.  His $O(p
  (m-p) \lg n)$ algorithm is based on using a band of width $m-p$ when the LCS
  has length at least $p$.


- Ukkonen [cite/text/cf:@ukkonen83 conference;@ukkonen85 paper] ::
  Introduces the diagonal transition method for edit costs, using $O(s\cdot
  \min(m,n))$ time and $O(s^2)$ space, and if only the score is needed, $O(s)$
  space.

  Concepts introduced:
  * $d_{ij}$ is non-decreasing on diagonals, and has bounded increments.
  * *Furthest reaching point*: Instead of storing $d$, we can store increments
    only: $f_{kp}$ is the largest $i$ s.t. $d_{ij}=p$ on diagonal $k$ ($j-i=k$).
    [TODO: they only generalize it from LCS elsewhere]
  * A recursion on $f_{kp}$ for unit costs, computing /wavefront/ $f_{\bullet,p}$ from
    the previous front $f_{\bullet, p-1}$, by first taking a maximum over
    insert/deletion/substitution options, and then increasing $f$ as long as
    characters on the diagonal are matching.

    Only $O(s^2)$ values of $f$ are computed, and if the alignment is not
    needed, only the last /front/ $f_{\bullet, p}$ is needed at each step.
  * *Gap heuristic*: The distance from $d_{ij}$ to the end $d_{nm}$ is at least
    $|(i-n)-(j-m)|\cdot \Delta$ when $\Delta$ is the cost of an indel.
    This allows pruning of some diagonals.

  Additionally, this paper introduces an algorithm that does exponential search
  on the band with, leading to an $O(ns)$ algorithm for general costs but using
  $O(ns)$ space.
- [cite/text/cf:@myers86], submitted '85 ::
  Independent of [cite/text:@ukkonen85], this
  introduces the concept of furthest reaching point and the
  recursion, but for LCS. Dijkstra's algorithm is used to evaluate DP states in
  order of increasing distance. $O(nd)$. For random strings, they show it runs in
  $O(n+d^2)$ expected time.

  Uses divide-and-conquer to achieve $O(n)$ space; see below.
- [cite/text/cf:@lv89], submitted '86 :: Extends [cite/text:@ukkonen85]
  to finding /all/ matches of a pattern in a text with at most $k$ errors, in
  $O(nm)$ time. They improve this to $O(nk)$ by using a suffix tree with LCA
  queries to extend matching diagonals in $O(1)$ instead of checking one
  character at a time.


- [cite/text/cf:@no-subquadratic-ed] ::
  Shows that edit distance can not be solved in time $O(n^{2-\delta})$
  for any $\delta > 0$, on the consition that the /Strong Exponential Time
  Hypothesis/ is true.

** Tools
Note: From 1990 to 2010 there is a gap without much theoretical progress on
exact alignment.
During this time, speedups were achieved by [TODO: citations]:
- more efficient implementations on available hardware;
- heuristic approaches such as banded alignment and $x$-drop.

There are many implementations of exact and inexact aligners. Here I will only
list current competitive aligners.

[TODO: This is very incomplete for now]

- Greedy matching :: todo
- Myers bit-parallel algorithm :: todo
- SeqAN :: todo
- Parasail :: todo
- Edlib :: A fast implementation (using Myers bit-parallel algorithm I believe)
- Block aligner :: approximate
- WFA :: exact, diagonal transition method

  States the recurrence for gap-affine costs for the diagonal transition
  algorithm, and provides a fast implementation. It is unclear to me why it took
  30+ years to merge the existing gap-affine recursion and more efficient
  diagonal-transition method.
- WFA2 :: Extends WFA to more cost models, more alignment modes, and introduces
  low-memory variants
- WFALM :: *L*ow *M*emory variant of WFA.

  Uses a square-root decomposition to do backtracking in $O(s^{3/2})$

  *Additional speedup:*
  The extension/greedy matching can be done using a precomputed suffixtree and LCA queries.
  This results in $O(n+m+s^2)$ complexity but is not faster in practice.
  [TODO: original place that does this]
- biWFA [WIP, unpublished] :: Meet-in-the-middle/divide-and-conquer variant of WFA, applying the ideas in
  [cite/text:@hirschberg75] to WFA to reconstruct the alignment in linear space.
- lh3/lv89 :: Similar to biWFA (but non-recursive) and WFALM (but with a fixed
  edit-distance between checkpoints, instead of dynamically storing every
  $2^{i}$ /th/ wavefront).

* References
#+print_bibliography:
