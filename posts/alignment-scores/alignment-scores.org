#+TITLE: [Draft] Turning match bonus into costs
#+HUGO_BASE_DIR: ../..
#+HUGO_TAGS: pairwise-alignment optimisation match-bonus alignment-scores
#+HUGO_LEVEL_OFFSET: 1
#+OPTIONS: ^:{}
#+hugo_auto_set_lastmod: nil
#+date: <2022-08-11>
#+author: Mykola Akulov
#+author: Ragnar Groot Koerkamp
#+hugo_front_matter_key_replace: author>authors
#+bibliography: local-bib.bib
#+cite_export: csl ../../chicago-author-date.csl
#+toc: headlines 3
# hide this post
#+hugo_custom_front_matter: :_build '((list . "never"))

* Tricks with match bonus or how to fool Dijkstra's limitations

/The reader is assumed to have basic knowledge about pairwise alignment and graph theory./

In this post we will show how to transform traditional alignment score models that include a match
bonus into an equivalent cost model using only non-negative costs. We generalize the relationship
in [cite/t:@wfalm] and show that it applies to both affine and asymmetric cost
models. Our method also does not increase the base penalties by a factor $2$,
leading to a lower cost alignment.

** Edit graph

The default global pairwise alignment task can be considered as the task of
finding a shortest path in the edit graph, as shown in [[edit-graph]].

#+NAME: edit-graph
#+CAPTION: The edit graph with match cost m=0, mismatch cost x, insertion cost i, and deletion cost d.
[[file:edit-graph.svg]]

Edges in this graph correspond to the cost you need to 'pay' for an insertion,
deletion, or mismatch of a letter. If two letters are the same, you can go through
a 'match' edge for free.
Since matches are free, it is allowed to greedily match characters whenever
possible without considering the insertion and deletion edges.
This
principle is the basis of the WFA algorithm, which can extend diagonals efficiently
because it does not check other operations.

#+NAME: edit-graph-negative
#+CAPTION: Edit graph with negative match cost m = -b.
[[file:edit-graph-negative.svg]]

In some cases, a negative match cost $m<0$ is used, where using a
match /decreases/ the cost of the alignment, as in [[edit-graph-negative]].
We call the positive number $b:=-m$ the /match bonus/.

** Algorithms

Let’s recall what algorithms can be used to compute the shortest path in an
edit graph.

- *Needleman-Wunsch*: $O(nm)$ approach based on dynamic programming that works for any cost model.
- *Dijkstra*: $O(ns)$ when used with a bucket-queue. Only works for non-negative
  edges, where $s$ is the edit distance.
- *WFA*: A more efficient variant of Dijkstra, using $O(ns)$ worst case, but
  $O(s^2)$ expected case. Also only works for non-negative edges.
- *A${}^*$*: usually faster than Dijkstra, but depends on chosen heuristic function.

[todo] A${}^*$ uses a heuristic, which can automatically compensate for negative edges, just
like potentials from Johnson’s algorithm, which will be discussed later. So
performing Dijkstra's algorithm on the graph modified by a given potential is
the same as performing A* with the corresponding heuristic function.

But introducing negative match bonus breaks things for Dijkstra’s algorithm, because it does not support graphs with negative edges. You may say that we can transform graph using Johnson’s algorithm, and that’s completely correct! But its asymptotic is $O(VE)$, which exceeds Dijkstra, so it would be inefficient.

** A solution

Our graph is weighted, directed, without cycles, and “all roads lead to Rome” in
it – any way you can take in the edit graph will end in the terminating point, to which we are trying find the shortest path.
And to get to this terminus we need to cross graph both vertically and horizontally for we go from upper left corner to down right one. And any path, will take the same number of steps down, and the same number of steps right. Insertion is one step down, deletion - one step right, mismatch or match - one step down and one step right. So if we will increase isertion edge cost by some number $\delta _ i$, deletion edge cost by some number $\delta _ d$,
 and mismatch and match cost by sum of theese numbers ($\delta _ i + \delta _ d$, then total cost of the alignment will go up $N\cdot \delta _ i + M\cdot \delta _ d$, where N is length of the first sequence ($N := |A|$), and M is length of the second sequence ($M := |B|$).
The conclusion is that every path has the same number of horizontal and vertical steps.

So instead of making negative match edge, we can tune other edges the way, that
will not alter the shortest path, but only change editing cost by a constant
value we know (yes, we are doing Johnson’s algorithm, but manually to speed it
up). To make match more “attractive” we need to increase cost of insertion and
deletion. Let $b := -m$ be match bonus, which is a positive number indicating
how much each match decreases the cost of the path.

So we can compensate match bonus by increasing weight of each insertion edge by $\delta _ i$, each deletion edge by $\delta _ d$ that **_$\delta _ i + \delta _ d = b$_**.

*** WFA
For WFA this method is a life-saver because it lets it keeps “greedy matching” – core of the algorithm, which enables fast extending diagonals (match is still the best option to take, and cost is still monotonously increasing. This is important, because one of the main WFA data structures is a wavefront, which covers all states that can be reached with specific cost. If the cost could go down, it could disrupt previous wavefronts, which would break the logic of the algorithm). But this trick increases cost -> increases number of wavefronts -> slows WFA down and increases needed for the algorithm amount of memory. The total cost will increase by some number. Let’s find it:

# #+NAME:
# #+CAPTION: Figure 3. edit graph with "tuned" non-negative edges. m = 0
[[file:3.svg]]

** Proof

\begin{align}
 i' &= i + \delta _ i\\
 d' &= d + \delta _ d\\
 N &= |A|\\
 M &= |B|
\end{align}
where $\delta _ i + \delta _ d = b$.

$N = |A|$ – length of the first sequence, constant

$M = |B|$ – length of the second sequence, constant

$\delta _ i + \delta _ d = b$ (adding additional cost to insertion + adding additional cost to deletion = match bonus; $c > 0$; $d > 0$; formula 1)

$$i' = i + \delta _ i$$

$$d' = d + \delta _ d$$

$s' = s + \delta _ i \cdot M + \delta _ d\cdot N$ - new cost ($s'$) is old cost ($s$) plus (increase of the insertion cost)*(length of the second seq) plus (increase of the deletion cost)*(length of the first seq)

$\delta _ d = b – \delta i$ (from formula 1)

$$s' = s + \delta _ i\cdot M + (b – \delta _ i)\cdot N$$

$$s' = s + \delta _ i\cdot (M – N) + b\cdot N$$

$s$ and $b\cdot N$ are constants, so to minimize $s'$, we need to minimize $\delta _ i\cdot (M – N)$.

Here, we need to consider several options:

1. $N = M$<br>In this case, expression $\delta _ i\cdot (M – N)$ is zero with any $\delta _ i$, so $\delta _ i$ and $\delta _ d$ can be taken arbitrary, so their sum should be $b$ (formula 1 is still in action). $\delta _ i = any$; $\delta _ d = any$; $\delta _ i + \delta _ d = b$<br>$s' = s + \delta _ i\cdot (M – N) + b\cdot N = s + b\cdot N$
2. $N > M$<br>In this case, $\delta _ i\cdot (M – N)$ is negative, which we need to exploit – we should take $\delta _ i = b$ to let $\delta _ i\cdot (M – N)$ (and $s'$ respectively) be minimal. $\delta _ i = b$; $\delta _ d = 0$<br>$s' = s + \delta _ i\cdot (M – N) + b\cdot N = s + b\cdot (M – N) + b\cdot N = s + b\cdot M$
3. $N < M$<br>In this case, $\delta _ i\cdot (M – N)$ is positive, which we need to compensate this – we should take $\delta _ i = 0$, to make $\delta _ i\cdot (M – N)$ zero and cost minimal. $\delta _ i = 0$; $\delta _ d = b$<br>$s' = s + \delta _ i\cdot (M – N) + b\cdot N = s + 0\cdot (M – N) + b\cdot N = s + b\cdot N$

So total cost will increase by $b*min(N, M)$.

For WFA and Dijkstra this is a serious slow down. For example, using unit cost $(insertion\_cost = 1; deletion\_cost = 1; mismatch\_cost = 1)$, cost does not exceed $max(N, M)$. Usually, $N ≈ M$, so this feature also slows WFA approximately in $(b+1)$ times.

*** Affine gap cost

Exactly the same logic can be applied to affine gap cost model: gap open/close costs will remain the same, while insertion gap extention cost and deletion gap extention cost will be increased by $\delta_i$ and $\delta_d$ respectively. The same rules of picking optimal $\delta_i$ and $\delta_d$ as in the previous chapter must be used.


** Potentials

The trick we used for Dijkstra is simplified version of potentials from Johnson’s algorithm. Potential is some number, attached to each vertex. And graph edges can be "tuned" using potentials to save all existing shortest pathes, but at the same time make edges non-negative.
$$E'(a,b) = E(a,b) + \phi(u) - \phi(v)$$
where $E(u,v)$ - cost of the edge from vertex $u$ to vertex $v$; $E'(u,v)$ - new cost of the edge from vertex $u$ to vertex $v$; $\phi(u)$ - potential at vertex $u$
Now, the question is how to calculate these potentials. Well, generally Johnson’s algorithm is used to calculate them for any arbitrary graph (without negative loops), but this operation has asymptotic of $O(VE)$, which is already more than Dijkstra, so we can't use just as it is.
But because our graph has some known structure, we can make a simple formula to calculate these potentials for each point, depending on where that point is located.
Let's assume we already chose our $\delta _ i$ and $\delta _ d$ values.

We also need to arrange our vertexes somehow. I'm sure you all noticed that our graph is a perfect grid, where each vertex takes predefined position and has a coordinate. So let's make a coordinate grid, and assign a coordinate $(x,y)$ for each vertex.

# #+NAME:
# #+CAPTION: Figure 4. Coordinate grid for vertexes
[[file:4.svg]]

Then the formula for potentials will look like this:
$$\phi(v) := -(v_x\cdot \delta_d + v_y\cdot \delta_i)$$, where $v_x$ is $x$ coordinate of vertex $v$, and $v_y$ is $y$ coordinate of vertex $v$.

** More figures and tables!

Firstly, let's make an experiment on sequences, where $N$ (length of the sequence 1) $> M$ (length of the sequence 2).
Our cost model will be the following:
- $i = 1$ - insertion cost
- $d = 1$ - deletion cost
- $s = 1$ - substitution cost
- $b = 2$ - match bonus

Knowing match bonus, we can take different $\delta _ i$ and $\delta _ d$. According to our theory, the optimal option should be $\delta _ i = 2; \delta _ d = 0$. Let's check that!
(_Note_: author's laptop was made in times of the Second Punic War, so he decided not to take very long sequences to save his working station)

|   N |   M | $\delta_i$ | $\delta_d$ | Cost | Time (ms) | number expanded |
| 260 | 199 | $0$        | $2$        | -275 |        26 |           92628 |
| 260 | 199 | $2$        | $0$        | -275 |         6 |           42610 |
| 260 | 199 | $1$        | $1$        | -275 |        11 |           48895 |


I think numbers are eloquent enough, so let's look at pixels:
#+NAME:
#+CAPTION: Figure 5. delta _ i = 0; \delta _ d = 2
#+CAPTION: Figure 7. delta _ i = 1; \delta _ d = 1
#+CAPTION: Figure 6. delta _ i = 2; \delta _ d = 0
| [[file:unequal_delta_i.png]] | [[file:unequal_delta_d.png]] | [[file:unequal_equal.png]] |

Second case is equal lengths of both strings.
|   N |   M | $\delta_i$ | $\delta_d$ | Cost | Time (ms) | number expanded |
| 200 | 200 | $0$        | $2$        | -323 |         4 |           45920 |
| 200 | 200 | $2$        | $0$        | -323 |         4 |           46020 |
| 200 | 200 | $1$        | $1$        | -323 |         3 |           34466 |

As expected, in this case $\delta _ i$ and $\delta _ d$ can be taken arbitrary, but we can see that experiments show that it is prefered in this case to split match bonus equally between $\delta _ i$ and $\delta _ d$.
Pictures for this case are so:
#+NAME:
#+CAPTION: Figure 8. delta _ i = 0; \delta _ d = 2
#+CAPTION: Figure 9. delta _ i = 2; \delta _ d = 0
#+CAPTION: Figure 10. delta _ i = 1; \delta _ d = 1
| [[file:equal_delta_i.png]]  | [[file:equal_delta_d.png]]  | [[file:equal_equal.png]]   |

# * References
# #+print_bibliography:
