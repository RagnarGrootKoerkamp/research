#+title: PTHash: Notes on implementing PTHash in Rust [ongoing]
#+HUGO_SECTION: notes
#+hugo_tags: mphf
#+HUGO_LEVEL_OFFSET: 1
#+OPTIONS: ^:{}
#+hugo_front_matter_key_replace: author>authors
#+toc: headlines 3
#+date: <2023-09-21>
#+author: Ragnar Groot Koerkamp

Daniel got me excited about minimal perfect hashing functions (MPHFs), and then
[[https://twitter.com/nomad421/status/1701593870734336290][+twitter+ Rob]] asked for rust a implementation of PTHash [cite:@pthash], and also
I have some ideas related to memory prefetching I want to play with, so here we
are: I'm working on a Rust implementation ~pthash-rs~ at [[https://github.com/ragnargrootkoerkamp/pthash-rs]].

This post is just to collect random thoughts and questions that come up while
writing the code.

Twitter discussion is [[https://twitter.com/curious_coding/status/1704989305158979656][here]].

(See also my [[file:bbhash.org][note on BBHash]] [cite:@bbhash].)

* Questions and remarks on PTHash paper
Probably some of these questions are answered by reading into the original FCH
paper [cite:@fch] -- that'll come at some later time.
- FCH uses $cm/\log_2 n$ buckets because each bucket needs $\log_2 n$ bits
  storage, but for PTHash the bits per bucket is lower so this isn't really the
  right formula maybe.
  - [[https://twitter.com/giulio_pibiri/status/1705114424787308718][Tweet]]: another option is to fix $c = \alpha * \log(n) / d$ for some constant
    $d$.
- FCH uses $\lceil cn / (\log_2n+1)\rceil$ buckets, but PTHash uses $\lceil
  cn/\log_2 n\rceil$ buckets. To me, $\lceil cn/\lceil \log_2n\rceil\rceil$
  actually sounds most intuitive.
- $p_1=0.6n$ and $p_2=0.3m$ seem somewhat arbitrary. Can this be tuned better?
  Could partitioning into more chunks help?

  Anyway, this puts $60\%$ of data in the first $30\%$ of buckets (i.e. double
  the average size), and $40\%$ of data in $70\%$ of buckets (i.e. roughly half
  the average size).

  I suppose the goal is to stitch two binomial distributions of bucket sizes
  together in a nice way to get a more even distribution over sizes.
  - This is an open question ([[https://twitter.com/giulio_pibiri/status/1705112904779915662][tweet]])
    - Proof in appendix of [[https://jermp.github.io/assets/pdf/papers/TKDE2023.pdf][paper]] could possibly be extended.

* Ideas for improvement
** Parameters
- Better tuning of parameters may work?
- Partitioning into three or more chunks may speed up construction?

** Align packed vectors to cachelines
Instead of packing $r$ bit values throughout the entire vector, only pack them
inside cachelines.

** Prefetching
The query performance of this and other MPHFs seem to be limited by the latency
of memory lookups. For this reason, most MPHFs minimize the number of memory
lookups, and in particular PTHash uses one random memory access followed by one
lookup in a small (cached) dictionary.

When processing a number of lookups sequentially, each lookup currently incurs a
cache miss. This could be made much more efficient by doing $k$ (e.g. $k=16$) cache
lookups in parallel:
1. first compute the array location to lookup for $k$ keys (possibly using SIMD),
2. then prefetch the $k$ memory locations,
3. then do the rest of the computation in parallel.
4. If needed, do lookups in the $free$ table in parallel.

This should mostly hide the memory latency and could give significant speedup.
I'm not quite sure yet whether this would work best when done in batches (as
described), or in streaming fashion, where we iterate over elements and prefetch
memory for the element $k$ iterations ahead. [[https://en.algorithmica.org/hpc/cpu-cache/prefetching/][Algorithmica.org]] has a nice article
on the streaming approach.

** Fewer modulo operations
There are a lot of ~% n~, ~% p1~ and ~% (m-p1)~ operations throughout the code.
I didn't look into it yet, but possibly these are the bottleneck on the CPU
latency.

First note that
$$
a\, \%\, b = a - \lfloor a/b\rfloor * b.
$$
This division by a constant can be computed efficiently using a trick which
replaces division by multiplication with the inversion.
Using the formula of the [[https://en.wikipedia.org/wiki/Division_algorithm#Division_by_a_constant][wikipedia article]] we can precompute some constants to
evaluate $\lfloor a/b\rfloor$ in $6$ operations and ~a % b~ in $8$ operations.

+(Note that it might be possible compilers already do this, but I don't expect so.)+

Some blogposts by Daniel Lemire ([[https://twitter.com/daniel_c0deb0t/status/1704999240802636051][Thanks Daniel Liu]] ;)
- [[https://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/][A fast alternative to the modulo reduction]]

  Instead of ~a % b~, compute ~a * b >> 64~, assuming that $a$ is uniform in
  $[2^{64}-1]$.

  This doesn't seem to work though, probably since this only uses the entropy in
  the high-order bits of $a$.
- [[https://lemire.me/blog/2019/02/08/faster-remainders-when-the-divisor-is-a-constant-beating-compilers-and-libdivide/][Faster remainders when the divisor is a constant: beating compilers and libdivide]]

  Indeed, the C++ PTHash implementation [[https://twitter.com/giulio_pibiri/status/1705104355270037980][already uses]] the =fastmod= library.

- [[https://lemire.me/blog/2019/02/20/more-fun-with-fast-remainders-when-the-divisor-is-a-constant/][More fun with fast remainders when the divisor is a constant]]
- [cite/t:@fast-remainder]

* Implementation log
A somewhat chronological list of notes and remarks.
** Hashing function
For now I use =murmur64a=.
** Bitpacking crates
There are *a lot* of bitvector and bitpacking crates!
- [[https://crates.io/search?q=bitvec][bitvectors]] :: All of the below seem to do the same
  - =bitvec=: $30M$ downloads
  - =bit-vec=: $30M$ downloads
  - =fixedbitset=: $55M$ downloads
  No idea which is best; probably I'll settle for the one below in =sucds=.
- [[https://crates.io/crates/sucds][sucds]] :: only $60K$ downloads, but contains
  - [[https://docs.rs/sucds/latest/sucds/bit_vectors/bit_vector/struct.BitVector.html][BitVector]]
  - fixed-width integer packing: [[https://docs.rs/sucds/latest/sucds/int_vectors/compact_vector/struct.CompactVector.html][CompactVector]]
  - increasing-integer sequence packing: [[https://docs.rs/sucds/latest/sucds/mii_sequences/index.html][EliasFano]]
    - Giulio has [[https://github.com/jermp/data_compression_course][lecture notes]] on this.

** Fastmod
It seems that Daniel Lemire's =fastmod= C++ library has not yet been ported to
Rust, so I converted the few parts I need.

There is also [[https://crates.io/crates/strength_reduce][=strength_reduce=]], which contains a similar but distinct algorithm
for ~a % b~ that computes the remainder from the quotient.

*** Benchmark
I [[https://github.com/RagnarGrootKoerkamp/pthash-rs/commit/c070936558e756bafaae92af5be31ac383f2c3ee][implemented]] these under a generic =Reduce= trait.

~just bench~ at the linked commit at ~2.6GHz~ gives the following for $10^7$ keys:

| method           | construction (s) | query (ns) |
| u64              |        10.474591 |         91 |
| fastmod64        |        10.731583 |         55 |
| fastmod32        |         9.911751 |         50 |
| strengthreduce64 |        11.520939 |         56 |
| strengthreduce32 |        10.002017 |         50 |

The =u32= versions simply only use the lower $32$ bits of the $64$ bit hash.

This is not yet as fast as the fastest $28ns$ reported in the PTHash paper (for
C-C encoding), but I also haven't optimized anything else yet.


** Construction
- Storing buckets as ~Vec<Vec<Key>>~ is bad for large keys, so now I store
  ~Vec<Vec<usize>>~, but the nested ~Vec~s still waste a lot of space and will
  cause allocation slowdowns. PTHash pushes onto a vector which is sorted later,
  which seems more efficient.
- When testing $k_i$, not only do we need to test that positions are not filled
  by previous buckets, but also we have to check that elements within the bucket
  do not collide. *It is not sufficient that $h(x, s)$ does not collide within
  buckets,* since they could collide after taking the ~% n~.


#+print_bibliography:
